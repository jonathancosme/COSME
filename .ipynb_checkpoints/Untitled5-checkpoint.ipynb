{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e16a2b7-52c1-4ab8-93ee-b8ad95e48444",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 05:20:29.960055: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-23 05:20:29.960350: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-23 05:20:29.960445: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "from global_funcs import load_program_config\n",
    "from glob import glob\n",
    "import os\n",
    "os.environ[\"TF_MEMORY_ALLOCATION\"] = \"0.7\"  # fraction of free memory\n",
    "os.environ[\"TF_VISIBLE_DEVICE\"] = \"0\"\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "from nvtabular.loader.tensorflow import KerasSequenceLoader, KerasSequenceValidater\n",
    "import tensorflow as tf\n",
    "import nvtabular as nvt\n",
    "import dask_cudf\n",
    "\n",
    "import rmm\n",
    "from nvtabular.utils import device_mem_size\n",
    "import shutil\n",
    "import pathlib\n",
    "from dask_cuda import LocalCUDACluster\n",
    "from dask.distributed import Client\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87e54b16-18b2-4fb3-881b-d69fe160918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 16384\n",
    "BATCH_SIZE = 4096\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08c744ab-f5a0-4de9-b87a-8cb125baa973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading configs...\n"
     ]
    }
   ],
   "source": [
    "print(\"loading configs...\")\n",
    "configs = load_program_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e772bf4-5973-469e-9e48-5b69fb500f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting variables...\n"
     ]
    }
   ],
   "source": [
    "print(\"setting variables...\")\n",
    "output_dir = configs['output_dir']\n",
    "project_name = configs['project_name']\n",
    "input_col_name = configs['input_col_name']\n",
    "label_col_name = configs['label_col_name']\n",
    "random_seed = configs['random_seed']\n",
    "data_splits = configs['data_splits']\n",
    "base_col_names = configs['base_col_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8896cc53-961b-42e9-8ca8-b4d7f07fff1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_in_pathname = f\"{output_dir}/{project_name}/nvtab\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56a44c47-46bb-4fc3-b9b8-5edc3728deb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:43581</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>1</li>\n",
       "  <li><b>Memory: </b>31.21 GiB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:43581' processes=1 threads=1, memory=31.21 GiB>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define some information about where to get our data\n",
    "dask_workdir = pathlib.Path(base_in_pathname, \"dask\", \"workdir\")\n",
    "stats_path = pathlib.Path(base_in_pathname, \"dask\", \"stats\")\n",
    "\n",
    "# Make sure we have a clean worker space for Dask\n",
    "if pathlib.Path.is_dir(dask_workdir):\n",
    "    shutil.rmtree(dask_workdir)\n",
    "dask_workdir.mkdir(parents=True)\n",
    "\n",
    "# Make sure we have a clean stats space for Dask\n",
    "if pathlib.Path.is_dir(stats_path):\n",
    "    shutil.rmtree(stats_path)\n",
    "stats_path.mkdir(parents=True)\n",
    "\n",
    "# Get device memory capacity\n",
    "capacity = device_mem_size(kind=\"total\")\n",
    "\n",
    "# Deploy a Single-Machine Multi-GPU Cluster\n",
    "protocol = \"tcp\"  # \"tcp\" or \"ucx\"\n",
    "visible_devices = \"0\"  # Delect devices to place workers\n",
    "device_spill_frac = 0.2  # Spill GPU-Worker memory to host at this limit.\n",
    "# Reduce if spilling fails to prevent\n",
    "# device memory errors.\n",
    "cluster = None  # (Optional) Specify existing scheduler port\n",
    "if cluster is None:\n",
    "    cluster = LocalCUDACluster(\n",
    "        protocol=protocol,\n",
    "        CUDA_VISIBLE_DEVICES=visible_devices,\n",
    "        local_directory=dask_workdir,\n",
    "        device_memory_limit=capacity * device_spill_frac,\n",
    "        rmm_pool_size='1GB'\n",
    "    )\n",
    "\n",
    "# Create the distributed client\n",
    "client = Client(cluster)\n",
    "client\n",
    "\n",
    "# # Initialize RMM pool on ALL workers\n",
    "# def _rmm_pool():\n",
    "#     rmm.reinitialize(\n",
    "#         pool_allocator=True,\n",
    "#         initial_pool_size=None,  # Use default size\n",
    "#     )\n",
    "\n",
    "\n",
    "# client.run(_rmm_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98cd897c-c6d4-4644-bdc5-98aecab5ee62",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATHS = sorted(glob(f\"{base_in_pathname}/train/*.parquet\"))\n",
    "VAL_PATHS = sorted(glob(f\"{base_in_pathname}/val/*.parquet\"))\n",
    "TEST_PATHS = sorted(glob(f\"{base_in_pathname}/test/*.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72ab53e4-44d0-4de2-866b-92f520f1c214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed them to our datasets\n",
    "train_dataset = KerasSequenceLoader(\n",
    "    nvt.Dataset(TRAIN_PATHS, part_size=\"100MB\"), # you could also use a glob pattern\n",
    "    # TRAIN_PATHS,\n",
    "    # cat_names=[input_col_name],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_names=[label_col_name],\n",
    "    shuffle=True,\n",
    "    buffer_size=0.001,  # amount of data, as a fraction of GPU memory, to load at once,\n",
    "    device=0,\n",
    "    parts_per_chunk=1,\n",
    "    engine=\"parquet\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b6a1bf6-3620-4806-809d-0e28f63846d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = KerasSequenceLoader(\n",
    "    nvt.Dataset(VAL_PATHS, part_size=\"100MB\"),   # you could also use a glob pattern\n",
    "    # VAL_PATHS,\n",
    "    # workflow.transform(cur_dataset),\n",
    "    # cat_names=[input_col_name],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_names=[label_col_name],\n",
    "    shuffle=False,\n",
    "    buffer_size=0.001,  # amount of data, as a fraction of GPU memory, to load at once,\n",
    "    device=0,\n",
    "    parts_per_chunk=1,\n",
    "    engine=\"parquet\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7641c463-657a-4ac4-a5e1-dc81e7a66db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {}\n",
    "inputs[input_col_name] = \\\n",
    "    (tf.keras.Input(name=f\"{input_col_name}__values\", dtype=tf.int64, shape=(1,)),\n",
    "     tf.keras.Input(name=f\"{input_col_name}__nnzs\", dtype=tf.int32, shape=(1,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f063450e-17da-49b6-926f-e78d7dd6e401",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 05:20:32.759528: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-23 05:20:32.760217: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-23 05:20:32.760482: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-23 05:20:32.760682: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-23 05:20:32.760985: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-23 05:20:32.761121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-23 05:20:32.761221: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-23 05:20:32.761294: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-05-23 05:20:32.761310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11468 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "inputs2 = tf.keras.layers.Lambda(lambda x: x['seq'][0])(inputs)\n",
    "throw_way = tf.keras.layers.Lambda(lambda x: x['seq'][1])(inputs)\n",
    "shape = [tf.shape(throw_way)[k] for k in range(2)]\n",
    "inputs2 = tf.reshape(inputs2, [shape[0], 150])\n",
    "inputs2 = tf.cast(inputs2, tf.float32)\n",
    "inputs2 = tf.expand_dims(inputs2, 0)\n",
    "inputs2 = tf.reshape(inputs2, [shape[0], 1, 150])\n",
    "inputs2 = tf.math.multiply(inputs2, 1/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b20106f-8699-42af-a155-f758900c51a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6b198fa-3b2f-41b7-b999-203a1b02cdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "from cosme_model import COSMELayer\n",
    "from global_funcs import load_model_config, load_program_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57c0e02e-b884-4124-be55-58beaaaca6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'preblock_filters': 64,\n",
       " 'preblock_kernel_sizes': [3, 5, 7, 9, 11, 13],\n",
       " 'preblock_pool_size': 2,\n",
       " 'idblock_kernel_sizes': [3, 5, 7, 9, 11, 13],\n",
       " 'idblock_filters': [64, 128, 256, 512],\n",
       " 'idblock_activation': 'gelu',\n",
       " 'idblock_avg_pool_size': 2,\n",
       " 'last_activation': 'softmax'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config = load_model_config()\n",
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f949820-0029-4f6b-91bd-e8a1398e5c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preblock_filters = model_config['preblock_filters']\n",
    "preblock_kernel_sizes = model_config['preblock_kernel_sizes']\n",
    "preblock_pool_size = model_config['preblock_pool_size']\n",
    "idblock_kernel_sizes = model_config['idblock_kernel_sizes']\n",
    "idblock_filters = model_config['idblock_filters']\n",
    "idblock_activation = model_config['idblock_activation']\n",
    "idblock_avg_pool_size = model_config['idblock_avg_pool_size']\n",
    "last_activation = model_config['last_activation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d6b13f3-8fbd-4e6f-a8c2-3f9c72b98e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = pd.read_csv(f\"{output_dir}/{project_name}/data/unq_labels.csv\" ).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71b1641e-dd1a-4f6b-8057-23b91cf43ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosme_layer = COSMELayer(\n",
    "                preblock_filters=preblock_filters,\n",
    "                preblock_kernel_sizes=preblock_kernel_sizes,\n",
    "                preblock_pool_size=preblock_pool_size,\n",
    "                idblock_kernel_sizes=idblock_kernel_sizes,\n",
    "                idblock_filters = idblock_filters,\n",
    "                idblock_activation=idblock_activation,\n",
    "                idblock_avg_pool_size=idblock_avg_pool_size,\n",
    "                last_activation=last_activation,\n",
    "                n_classes=n_classes,\n",
    "                )\n",
    "output_layer = cosme_layer(inputs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22cae90d-7cb0-4876-9f21-c4c87ecc3ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=inputs, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59232dca-3127-4678-bd18-5bcd717fa1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE, amsgrad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58b3ed4f-ba4f-4abc-9acd-0ad1b9ad5292",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer, \n",
    "              tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), \n",
    "              metrics=['sparse_categorical_accuracy'],\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14c75247-496a-4939-b153-cdf8b7da666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_callback = KerasSequenceValidater(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "560b0397-b96f-4a32-b636-e77c8a1bf780",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8138b7e6-ea0b-4380-903b-fdc7e5223460",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TENSORBOARD_BINARY'] = '/home/jcosme/miniconda3/envs/tf/bin/tensorboard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4be6dfb2-d560-44e3-872a-145c3d122d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ddb10b731ab0c848\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ddb10b731ab0c848\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir tf_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53940796-afa4-4a99-b778-01b6fff1d0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"tf_logs\"\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28d08c2d-2fbd-4b4d-a69d-e459b8ee4297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 111/3267 [>.............................] - ETA: 54:52 - loss: 18.4874 - sparse_categorical_accuracy: 0.2499"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.nanny - WARNING - Restarting worker\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16917/847017698.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalidation_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensorboard_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2454\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2456\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1861\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[validation_callback, tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704a1257-b0b8-45a1-b96c-416d6f24a9d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9e40fdb-008d-4bc6-802d-6168e8a92772",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-18 12:54:22.784761: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-18 12:54:22.785084: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-18 12:54:22.785196: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "from global_funcs import load_data_config\n",
    "from glob import glob\n",
    "import os\n",
    "os.environ[\"TF_MEMORY_ALLOCATION\"] = \"0.7\"  # fraction of free memory\n",
    "os.environ[\"TF_VISIBLE_DEVICE\"] = \"0\"\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "from nvtabular.loader.tensorflow import KerasSequenceLoader, KerasSequenceValidater\n",
    "import tensorflow as tf\n",
    "import nvtabular as nvt\n",
    "import dask_cudf\n",
    "\n",
    "# import rmm\n",
    "# from nvtabular.utils import device_mem_size\n",
    "# import shutil\n",
    "# import pathlib\n",
    "from dask_cuda import LocalCUDACluster\n",
    "from dask.distributed import Client\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a323508f-0cca-4b7d-9a32-ad837c5cfa85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading configs...\n"
     ]
    }
   ],
   "source": [
    "print(\"loading configs...\")\n",
    "configs = load_data_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de95358f-ecaf-4fb5-b97c-98fc3c76e1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting variables...\n"
     ]
    }
   ],
   "source": [
    "print(\"setting variables...\")\n",
    "output_dir = configs['output_dir']\n",
    "project_name = configs['project_name']\n",
    "input_col_name = configs['input_col_name']\n",
    "label_col_name = configs['label_col_name']\n",
    "random_seed = configs['random_seed']\n",
    "data_splits = configs['data_splits']\n",
    "base_col_names = configs['base_col_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d93b5642-226d-4580-a360-39f00b822ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_in_pathname = f\"{output_dir}/{project_name}/nvtab\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e14eba30-9dfa-4579-82d5-e2ff68c51ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:45669</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>1</li>\n",
       "  <li><b>Memory: </b>31.21 GiB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:45669' processes=1 threads=1, memory=31.21 GiB>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # define some information about where to get our data\n",
    "# dask_workdir = pathlib.Path(base_in_pathname, \"dask\", \"workdir\")\n",
    "# stats_path = pathlib.Path(base_in_pathname, \"dask\", \"stats\")\n",
    "\n",
    "# # Make sure we have a clean worker space for Dask\n",
    "# if pathlib.Path.is_dir(dask_workdir):\n",
    "#     shutil.rmtree(dask_workdir)\n",
    "# dask_workdir.mkdir(parents=True)\n",
    "\n",
    "# # Make sure we have a clean stats space for Dask\n",
    "# if pathlib.Path.is_dir(stats_path):\n",
    "#     shutil.rmtree(stats_path)\n",
    "# stats_path.mkdir(parents=True)\n",
    "\n",
    "# # Get device memory capacity\n",
    "# capacity = device_mem_size(kind=\"total\")\n",
    "\n",
    "# # Deploy a Single-Machine Multi-GPU Cluster\n",
    "# protocol = \"tcp\"  # \"tcp\" or \"ucx\"\n",
    "# visible_devices = \"0\"  # Delect devices to place workers\n",
    "# device_spill_frac = 0.2  # Spill GPU-Worker memory to host at this limit.\n",
    "# # Reduce if spilling fails to prevent\n",
    "# # device memory errors.\n",
    "# cluster = None  # (Optional) Specify existing scheduler port\n",
    "# if cluster is None:\n",
    "#     cluster = LocalCUDACluster(\n",
    "#         protocol=protocol,\n",
    "#         CUDA_VISIBLE_DEVICES=visible_devices,\n",
    "#         local_directory=dask_workdir,\n",
    "#         device_memory_limit=capacity * device_spill_frac,\n",
    "#         rmm_pool_size='1GB'\n",
    "#     )\n",
    "\n",
    "# # Create the distributed client\n",
    "# client = Client(cluster)\n",
    "# client\n",
    "\n",
    "# # # Initialize RMM pool on ALL workers\n",
    "# # def _rmm_pool():\n",
    "# #     rmm.reinitialize(\n",
    "# #         pool_allocator=True,\n",
    "# #         initial_pool_size=None,  # Use default size\n",
    "# #     )\n",
    "\n",
    "\n",
    "# # client.run(_rmm_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fd082c-83f7-4d09-8ca3-de1f6d6d49c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCUDACluster()\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a509d351-c6ec-453a-9765-aa415d43b0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATHS = sorted(glob(f\"{base_in_pathname}/train/*.parquet\"))\n",
    "VAL_PATHS = sorted(glob(f\"{base_in_pathname}/val/*.parquet\"))\n",
    "TEST_PATHS = sorted(glob(f\"{base_in_pathname}/test/*.parquet\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db0fe680-190a-4aff-bc71-db6a0f4b1688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/jcosme/Data/full_mer_1/nvtab/test/part_0.parquet']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a08b109e-811f-4668-9bca-cc781f116d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16384\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c80f542-9be7-48af-b584-119049ace87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# workflow = nvt.Workflow.load(f\"{base_in_pathname}/workflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f85dc9d5-ae55-4096-a1a7-7f521311ee7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dask_cudf.read_parquet(f\"{base_in_pathname}/val\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e88c65ab-91eb-4455-ab82-45484aa0fbeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feed them to our datasets\n",
    "train_dataset = KerasSequenceLoader(\n",
    "    nvt.Dataset(TRAIN_PATHS, part_size=\"100MB\"), # you could also use a glob pattern\n",
    "    # TRAIN_PATHS,\n",
    "    # cat_names=[input_col_name],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_names=[label_col_name],\n",
    "    shuffle=True,\n",
    "    buffer_size=0.001,  # amount of data, as a fraction of GPU memory, to load at once,\n",
    "    device=0,\n",
    "    parts_per_chunk=1,\n",
    "    engine=\"parquet\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eaef00a7-6ba6-47a7-91bf-aceba802d93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = KerasSequenceLoader(\n",
    "    nvt.Dataset(VAL_PATHS, part_size=\"100MB\"),   # you could also use a glob pattern\n",
    "    # VAL_PATHS,\n",
    "    # workflow.transform(cur_dataset),\n",
    "    # cat_names=[input_col_name],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_names=[label_col_name],\n",
    "    shuffle=False,\n",
    "    buffer_size=0.001,  # amount of data, as a fraction of GPU memory, to load at once,\n",
    "    device=0,\n",
    "    parts_per_chunk=1,\n",
    "    engine=\"parquet\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f8fb3ab-861c-4188-8178-03f039c25bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = KerasSequenceLoader(\n",
    "    nvt.Dataset(TEST_PATHS, part_size=\"100MB\"),   # you could also use a glob pattern\n",
    "    # TEST_PATHS,\n",
    "    # cat_names=[input_col_name],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_names=[label_col_name],\n",
    "    shuffle=False,\n",
    "    buffer_size=0.06,  # amount of data, as a fraction of GPU memory, to load at once\n",
    "    engine=\"parquet\",\n",
    "    parts_per_chunk=1,\n",
    "    device=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25733d13-51d1-4a83-aae3-dabf19605612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec93760b-2919-46b1-b7f6-0fb797f5a130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = next(iter(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f8eabcd-c577-44a3-8550-7ffd46473ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d796a050-ae71-4a88-a61d-ff41449796df",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {}\n",
    "inputs[input_col_name] = \\\n",
    "    (tf.keras.Input(name=f\"{input_col_name}__values\", dtype=tf.int64, shape=(1,)),\n",
    "     tf.keras.Input(name=f\"{input_col_name}__nnzs\", dtype=tf.int32, shape=(1,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2c1c083-dde2-436f-ad52-df8bc0eecf90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-18 12:54:25.929777: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-18 12:54:25.930643: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-18 12:54:25.930885: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-18 12:54:25.930995: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-18 12:54:25.931280: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-18 12:54:25.931407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-18 12:54:25.931520: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-18 12:54:25.931603: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-05-18 12:54:25.931630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11468 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "inputs2 = tf.keras.layers.Lambda(lambda x: x['seq'][0])(inputs)\n",
    "throw_way = tf.keras.layers.Lambda(lambda x: x['seq'][1])(inputs)\n",
    "shape = [tf.shape(throw_way)[k] for k in range(2)]\n",
    "inputs2 = tf.reshape(inputs2, [shape[0], 150])\n",
    "inputs2 = tf.cast(inputs2, tf.float32)\n",
    "inputs2 = tf.expand_dims(inputs2, 0)\n",
    "inputs2 = tf.reshape(inputs2, [shape[0], 1, 150])\n",
    "inputs2 = tf.math.multiply(inputs2, 1/4)\n",
    "# inputs2 = tf.transpose(inputs2)\n",
    "\n",
    "# inputs2 = tf.keras.layers.Lambda(lambda x: tf.split(x, 32))(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b78436-f93e-4644-a3b1-f813d1d34640",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d541ff57-3189-4152-9033-e1ddd7e65c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = pd.read_csv(f\"{output_dir}/{project_name}/data/unq_labels.csv\" ).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "516c9475-c6f8-4406-9f3b-95b164a60eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_layer = tf.keras.layers.Input(shape=(1,150,), batch_size= dtype=tf.float32)\n",
    "\n",
    "preblock_a = tf.keras.layers.Conv1D(filters=64, kernel_size=3, padding='SAME')(inputs2)\n",
    "preblock_a = tf.keras.layers.BatchNormalization()(preblock_a)\n",
    "preblock_a = tf.keras.layers.Activation('gelu')(preblock_a)\n",
    "preblock_a = tf.keras.layers.MaxPool1D(pool_size=2, padding='SAME')(preblock_a)\n",
    "\n",
    "\n",
    "# block 1\n",
    "block_1_1_a = tf.keras.layers.Conv1D(filters=64, kernel_size=3, padding='SAME')(preblock_a)\n",
    "block_1_1_a = tf.keras.layers.BatchNormalization()(block_1_1_a)\n",
    "block_1_1_a = tf.keras.layers.Activation('gelu')(block_1_1_a)\n",
    "block_1_1_a = tf.keras.layers.Conv1D(filters=64, kernel_size=3, padding='SAME')(block_1_1_a)\n",
    "block_1_1_a = tf.keras.layers.BatchNormalization()(block_1_1_a)\n",
    "block_1_1_a = tf.keras.layers.Concatenate()([block_1_1_a, preblock_a])\n",
    "block_1_1_a = tf.keras.layers.Activation('gelu')(block_1_1_a)\n",
    "\n",
    "block_1_2_a = tf.keras.layers.Conv1D(filters=128, kernel_size=3, padding='SAME')(block_1_1_a)\n",
    "block_1_2_a = tf.keras.layers.BatchNormalization()(block_1_2_a)\n",
    "block_1_2_a = tf.keras.layers.Activation('gelu')(block_1_2_a)\n",
    "block_1_2_a = tf.keras.layers.Conv1D(filters=128, kernel_size=3, padding='SAME')(block_1_2_a)\n",
    "block_1_2_a = tf.keras.layers.BatchNormalization()(block_1_2_a)\n",
    "block_1_2_a = tf.keras.layers.Concatenate()([block_1_2_a, block_1_1_a])\n",
    "block_1_2_a = tf.keras.layers.Activation('gelu')(block_1_2_a)\n",
    "\n",
    "block_1_3_a = tf.keras.layers.Conv1D(filters=256, kernel_size=3, padding='SAME')(block_1_2_a)\n",
    "block_1_3_a = tf.keras.layers.BatchNormalization()(block_1_3_a)\n",
    "block_1_3_a = tf.keras.layers.Activation('gelu')(block_1_3_a)\n",
    "block_1_3_a = tf.keras.layers.Conv1D(filters=256, kernel_size=3, padding='SAME')(block_1_3_a)\n",
    "block_1_3_a = tf.keras.layers.BatchNormalization()(block_1_3_a)\n",
    "block_1_3_a = tf.keras.layers.Concatenate()([block_1_3_a, block_1_2_a])\n",
    "block_1_3_a = tf.keras.layers.Activation('gelu')(block_1_3_a)\n",
    "\n",
    "block_1_4_a = tf.keras.layers.Conv1D(filters=512, kernel_size=3, padding='SAME')(block_1_3_a)\n",
    "block_1_4_a = tf.keras.layers.BatchNormalization()(block_1_4_a)\n",
    "block_1_4_a = tf.keras.layers.Activation('gelu')(block_1_4_a)\n",
    "block_1_4_a = tf.keras.layers.Conv1D(filters=512, kernel_size=3, padding='SAME')(block_1_4_a)\n",
    "block_1_4_a = tf.keras.layers.BatchNormalization()(block_1_4_a)\n",
    "block_1_4_a = tf.keras.layers.Concatenate()([block_1_4_a, block_1_3_a])\n",
    "block_1_4_a = tf.keras.layers.Activation('gelu')(block_1_4_a)\n",
    "\n",
    "block_1_4_a = tf.keras.layers.AveragePooling1D(pool_size=2, padding='SAME')(block_1_4_a)\n",
    "\n",
    "\n",
    "# block 2\n",
    "block_2_1_a = tf.keras.layers.Conv1D(filters=64, kernel_size=5, padding='SAME')(preblock_a)\n",
    "block_2_1_a = tf.keras.layers.BatchNormalization()(block_2_1_a)\n",
    "block_2_1_a = tf.keras.layers.Activation('gelu')(block_2_1_a)\n",
    "block_2_1_a = tf.keras.layers.Conv1D(filters=64, kernel_size=5, padding='SAME')(block_2_1_a)\n",
    "block_2_1_a = tf.keras.layers.BatchNormalization()(block_2_1_a)\n",
    "block_2_1_a = tf.keras.layers.Concatenate()([block_2_1_a, preblock_a])\n",
    "block_2_1_a = tf.keras.layers.Activation('gelu')(block_2_1_a)\n",
    "\n",
    "block_2_2_a = tf.keras.layers.Conv1D(filters=128, kernel_size=5, padding='SAME')(block_2_1_a)\n",
    "block_2_2_a = tf.keras.layers.BatchNormalization()(block_2_2_a)\n",
    "block_2_2_a = tf.keras.layers.Activation('gelu')(block_2_2_a)\n",
    "block_2_2_a = tf.keras.layers.Conv1D(filters=128, kernel_size=5, padding='SAME')(block_2_2_a)\n",
    "block_2_2_a = tf.keras.layers.BatchNormalization()(block_2_2_a)\n",
    "block_2_2_a = tf.keras.layers.Concatenate()([block_2_2_a, block_2_1_a])\n",
    "block_2_2_a = tf.keras.layers.Activation('gelu')(block_2_2_a)\n",
    "\n",
    "block_2_3_a = tf.keras.layers.Conv1D(filters=256, kernel_size=5, padding='SAME')(block_2_2_a)\n",
    "block_2_3_a = tf.keras.layers.BatchNormalization()(block_2_3_a)\n",
    "block_2_3_a = tf.keras.layers.Activation('gelu')(block_2_3_a)\n",
    "block_2_3_a = tf.keras.layers.Conv1D(filters=256, kernel_size=5, padding='SAME')(block_2_3_a)\n",
    "block_2_3_a = tf.keras.layers.BatchNormalization()(block_2_3_a)\n",
    "block_2_3_a = tf.keras.layers.Concatenate()([block_2_3_a, block_2_2_a])\n",
    "block_2_3_a = tf.keras.layers.Activation('gelu')(block_2_3_a)\n",
    "\n",
    "block_2_4_a = tf.keras.layers.Conv1D(filters=512, kernel_size=5, padding='SAME')(block_2_3_a)\n",
    "block_2_4_a = tf.keras.layers.BatchNormalization()(block_2_4_a)\n",
    "block_2_4_a = tf.keras.layers.Activation('gelu')(block_2_4_a)\n",
    "block_2_4_a = tf.keras.layers.Conv1D(filters=512, kernel_size=5, padding='SAME')(block_2_4_a)\n",
    "block_2_4_a = tf.keras.layers.BatchNormalization()(block_2_4_a)\n",
    "block_2_4_a = tf.keras.layers.Concatenate()([block_2_4_a, block_2_3_a])\n",
    "block_2_4_a = tf.keras.layers.Activation('gelu')(block_2_4_a)\n",
    "\n",
    "block_2_4_a = tf.keras.layers.AveragePooling1D(pool_size=2, padding='SAME')(block_2_4_a)\n",
    "\n",
    "# block 3\n",
    "block_3_1_a = tf.keras.layers.Conv1D(filters=64, kernel_size=7, padding='SAME')(preblock_a)\n",
    "block_3_1_a = tf.keras.layers.BatchNormalization()(block_3_1_a)\n",
    "block_3_1_a = tf.keras.layers.Activation('gelu')(block_3_1_a)\n",
    "block_3_1_a = tf.keras.layers.Conv1D(filters=64, kernel_size=7, padding='SAME')(block_3_1_a)\n",
    "block_3_1_a = tf.keras.layers.BatchNormalization()(block_3_1_a)\n",
    "block_3_1_a = tf.keras.layers.Concatenate()([block_3_1_a, preblock_a])\n",
    "block_3_1_a = tf.keras.layers.Activation('gelu')(block_3_1_a)\n",
    "\n",
    "block_3_2_a = tf.keras.layers.Conv1D(filters=128, kernel_size=7, padding='SAME')(block_3_1_a)\n",
    "block_3_2_a = tf.keras.layers.BatchNormalization()(block_3_2_a)\n",
    "block_3_2_a = tf.keras.layers.Activation('gelu')(block_3_2_a)\n",
    "block_3_2_a = tf.keras.layers.Conv1D(filters=128, kernel_size=7, padding='SAME')(block_3_2_a)\n",
    "block_3_2_a = tf.keras.layers.BatchNormalization()(block_3_2_a)\n",
    "block_3_2_a = tf.keras.layers.Concatenate()([block_3_2_a, block_3_1_a])\n",
    "block_3_2_a = tf.keras.layers.Activation('gelu')(block_3_2_a)\n",
    "\n",
    "block_3_3_a = tf.keras.layers.Conv1D(filters=256, kernel_size=7, padding='SAME')(block_3_2_a)\n",
    "block_3_3_a = tf.keras.layers.BatchNormalization()(block_3_3_a)\n",
    "block_3_3_a = tf.keras.layers.Activation('gelu')(block_3_3_a)\n",
    "block_3_3_a = tf.keras.layers.Conv1D(filters=256, kernel_size=7, padding='SAME')(block_3_3_a)\n",
    "block_3_3_a = tf.keras.layers.BatchNormalization()(block_3_3_a)\n",
    "block_3_3_a = tf.keras.layers.Concatenate()([block_3_3_a, block_3_2_a])\n",
    "block_3_3_a = tf.keras.layers.Activation('gelu')(block_3_3_a)\n",
    "\n",
    "block_3_4_a = tf.keras.layers.Conv1D(filters=512, kernel_size=7, padding='SAME')(block_3_3_a)\n",
    "block_3_4_a = tf.keras.layers.BatchNormalization()(block_3_4_a)\n",
    "block_3_4_a = tf.keras.layers.Activation('gelu')(block_3_4_a)\n",
    "block_3_4_a = tf.keras.layers.Conv1D(filters=512, kernel_size=7, padding='SAME')(block_3_4_a)\n",
    "block_3_4_a = tf.keras.layers.BatchNormalization()(block_3_4_a)\n",
    "block_3_4_a = tf.keras.layers.Concatenate()([block_3_4_a, block_3_3_a])\n",
    "block_3_4_a = tf.keras.layers.Activation('gelu')(block_3_4_a)\n",
    "\n",
    "block_3_4_a = tf.keras.layers.AveragePooling1D(pool_size=2, padding='SAME')(block_3_4_a)\n",
    "\n",
    "preblock_b = tf.keras.layers.Conv1D(filters=64, kernel_size=5, padding='SAME')(inputs2)\n",
    "preblock_b = tf.keras.layers.BatchNormalization()(preblock_b)\n",
    "preblock_b = tf.keras.layers.Activation('gelu')(preblock_b)\n",
    "preblock_b = tf.keras.layers.MaxPool1D(pool_size=2, padding='SAME')(preblock_b)\n",
    "\n",
    "\n",
    "# block 1\n",
    "block_1_1_b = tf.keras.layers.Conv1D(filters=64, kernel_size=3, padding='SAME')(preblock_b)\n",
    "block_1_1_b = tf.keras.layers.BatchNormalization()(block_1_1_b)\n",
    "block_1_1_b = tf.keras.layers.Activation('gelu')(block_1_1_b)\n",
    "block_1_1_b = tf.keras.layers.Conv1D(filters=64, kernel_size=3, padding='SAME')(block_1_1_b)\n",
    "block_1_1_b = tf.keras.layers.BatchNormalization()(block_1_1_b)\n",
    "block_1_1_b = tf.keras.layers.Concatenate()([block_1_1_b, preblock_b])\n",
    "block_1_1_b = tf.keras.layers.Activation('gelu')(block_1_1_b)\n",
    "\n",
    "block_1_2_b = tf.keras.layers.Conv1D(filters=128, kernel_size=3, padding='SAME')(block_1_1_b)\n",
    "block_1_2_b = tf.keras.layers.BatchNormalization()(block_1_2_b)\n",
    "block_1_2_b = tf.keras.layers.Activation('gelu')(block_1_2_b)\n",
    "block_1_2_b = tf.keras.layers.Conv1D(filters=128, kernel_size=3, padding='SAME')(block_1_2_b)\n",
    "block_1_2_b = tf.keras.layers.BatchNormalization()(block_1_2_b)\n",
    "block_1_2_b = tf.keras.layers.Concatenate()([block_1_2_b, block_1_1_b])\n",
    "block_1_2_b = tf.keras.layers.Activation('gelu')(block_1_2_b)\n",
    "\n",
    "block_1_3_b = tf.keras.layers.Conv1D(filters=256, kernel_size=3, padding='SAME')(block_1_2_b)\n",
    "block_1_3_b = tf.keras.layers.BatchNormalization()(block_1_3_b)\n",
    "block_1_3_b = tf.keras.layers.Activation('gelu')(block_1_3_b)\n",
    "block_1_3_b = tf.keras.layers.Conv1D(filters=256, kernel_size=3, padding='SAME')(block_1_3_b)\n",
    "block_1_3_b = tf.keras.layers.BatchNormalization()(block_1_3_b)\n",
    "block_1_3_b = tf.keras.layers.Concatenate()([block_1_3_b, block_1_2_b])\n",
    "block_1_3_b = tf.keras.layers.Activation('gelu')(block_1_3_b)\n",
    "\n",
    "block_1_4_b = tf.keras.layers.Conv1D(filters=512, kernel_size=3, padding='SAME')(block_1_3_b)\n",
    "block_1_4_b = tf.keras.layers.BatchNormalization()(block_1_4_b)\n",
    "block_1_4_b = tf.keras.layers.Activation('gelu')(block_1_4_b)\n",
    "block_1_4_b = tf.keras.layers.Conv1D(filters=512, kernel_size=3, padding='SAME')(block_1_4_b)\n",
    "block_1_4_b = tf.keras.layers.BatchNormalization()(block_1_4_b)\n",
    "block_1_4_b = tf.keras.layers.Concatenate()([block_1_4_b, block_1_3_b])\n",
    "block_1_4_b = tf.keras.layers.Activation('gelu')(block_1_4_b)\n",
    "\n",
    "block_1_4_b = tf.keras.layers.AveragePooling1D(pool_size=2, padding='SAME')(block_1_4_b)\n",
    "\n",
    "\n",
    "# block 2\n",
    "block_2_1_b = tf.keras.layers.Conv1D(filters=64, kernel_size=5, padding='SAME')(preblock_b)\n",
    "block_2_1_b = tf.keras.layers.BatchNormalization()(block_2_1_b)\n",
    "block_2_1_b = tf.keras.layers.Activation('gelu')(block_2_1_b)\n",
    "block_2_1_b = tf.keras.layers.Conv1D(filters=64, kernel_size=5, padding='SAME')(block_2_1_b)\n",
    "block_2_1_b = tf.keras.layers.BatchNormalization()(block_2_1_b)\n",
    "block_2_1_b = tf.keras.layers.Concatenate()([block_2_1_b, preblock_b])\n",
    "block_2_1_b = tf.keras.layers.Activation('gelu')(block_2_1_b)\n",
    "\n",
    "block_2_2_b = tf.keras.layers.Conv1D(filters=128, kernel_size=5, padding='SAME')(block_2_1_b)\n",
    "block_2_2_b = tf.keras.layers.BatchNormalization()(block_2_2_b)\n",
    "block_2_2_b = tf.keras.layers.Activation('gelu')(block_2_2_b)\n",
    "block_2_2_b = tf.keras.layers.Conv1D(filters=128, kernel_size=5, padding='SAME')(block_2_2_b)\n",
    "block_2_2_b = tf.keras.layers.BatchNormalization()(block_2_2_b)\n",
    "block_2_2_b = tf.keras.layers.Concatenate()([block_2_2_b, block_2_1_b])\n",
    "block_2_2_b = tf.keras.layers.Activation('gelu')(block_2_2_b)\n",
    "\n",
    "block_2_3_b = tf.keras.layers.Conv1D(filters=256, kernel_size=5, padding='SAME')(block_2_2_b)\n",
    "block_2_3_b = tf.keras.layers.BatchNormalization()(block_2_3_b)\n",
    "block_2_3_b = tf.keras.layers.Activation('gelu')(block_2_3_b)\n",
    "block_2_3_b = tf.keras.layers.Conv1D(filters=256, kernel_size=5, padding='SAME')(block_2_3_b)\n",
    "block_2_3_b = tf.keras.layers.BatchNormalization()(block_2_3_b)\n",
    "block_2_3_b = tf.keras.layers.Concatenate()([block_2_3_b, block_2_2_b])\n",
    "block_2_3_b = tf.keras.layers.Activation('gelu')(block_2_3_b)\n",
    "\n",
    "block_2_4_b = tf.keras.layers.Conv1D(filters=512, kernel_size=5, padding='SAME')(block_2_3_b)\n",
    "block_2_4_b = tf.keras.layers.BatchNormalization()(block_2_4_b)\n",
    "block_2_4_b = tf.keras.layers.Activation('gelu')(block_2_4_b)\n",
    "block_2_4_b = tf.keras.layers.Conv1D(filters=512, kernel_size=5, padding='SAME')(block_2_4_b)\n",
    "block_2_4_b = tf.keras.layers.BatchNormalization()(block_2_4_b)\n",
    "block_2_4_b = tf.keras.layers.Concatenate()([block_2_4_b, block_2_3_b])\n",
    "block_2_4_b = tf.keras.layers.Activation('gelu')(block_2_4_b)\n",
    "\n",
    "block_2_4_b = tf.keras.layers.AveragePooling1D(pool_size=2, padding='SAME')(block_2_4_b)\n",
    "\n",
    "# block 3\n",
    "block_3_1_b = tf.keras.layers.Conv1D(filters=64, kernel_size=7, padding='SAME')(preblock_b)\n",
    "block_3_1_b = tf.keras.layers.BatchNormalization()(block_3_1_b)\n",
    "block_3_1_b = tf.keras.layers.Activation('gelu')(block_3_1_b)\n",
    "block_3_1_b = tf.keras.layers.Conv1D(filters=64, kernel_size=7, padding='SAME')(block_3_1_b)\n",
    "block_3_1_b = tf.keras.layers.BatchNormalization()(block_3_1_b)\n",
    "block_3_1_b = tf.keras.layers.Concatenate()([block_3_1_b, preblock_b])\n",
    "block_3_1_b = tf.keras.layers.Activation('gelu')(block_3_1_b)\n",
    "\n",
    "block_3_2_b = tf.keras.layers.Conv1D(filters=128, kernel_size=7, padding='SAME')(block_3_1_b)\n",
    "block_3_2_b = tf.keras.layers.BatchNormalization()(block_3_2_b)\n",
    "block_3_2_b = tf.keras.layers.Activation('gelu')(block_3_2_b)\n",
    "block_3_2_b = tf.keras.layers.Conv1D(filters=128, kernel_size=7, padding='SAME')(block_3_2_b)\n",
    "block_3_2_b = tf.keras.layers.BatchNormalization()(block_3_2_b)\n",
    "block_3_2_b = tf.keras.layers.Concatenate()([block_3_2_b, block_3_1_b])\n",
    "block_3_2_b = tf.keras.layers.Activation('gelu')(block_3_2_b)\n",
    "\n",
    "block_3_3_b = tf.keras.layers.Conv1D(filters=256, kernel_size=7, padding='SAME')(block_3_2_b)\n",
    "block_3_3_b = tf.keras.layers.BatchNormalization()(block_3_3_b)\n",
    "block_3_3_b = tf.keras.layers.Activation('gelu')(block_3_3_b)\n",
    "block_3_3_b = tf.keras.layers.Conv1D(filters=256, kernel_size=7, padding='SAME')(block_3_3_b)\n",
    "block_3_3_b = tf.keras.layers.BatchNormalization()(block_3_3_b)\n",
    "block_3_3_b = tf.keras.layers.Concatenate()([block_3_3_b, block_3_2_b])\n",
    "block_3_3_b = tf.keras.layers.Activation('gelu')(block_3_3_b)\n",
    "\n",
    "block_3_4_b = tf.keras.layers.Conv1D(filters=512, kernel_size=7, padding='SAME')(block_3_3_b)\n",
    "block_3_4_b = tf.keras.layers.BatchNormalization()(block_3_4_b)\n",
    "block_3_4_b = tf.keras.layers.Activation('gelu')(block_3_4_b)\n",
    "block_3_4_b = tf.keras.layers.Conv1D(filters=512, kernel_size=7, padding='SAME')(block_3_4_b)\n",
    "block_3_4_b = tf.keras.layers.BatchNormalization()(block_3_4_b)\n",
    "block_3_4_b = tf.keras.layers.Concatenate()([block_3_4_b, block_3_3_b])\n",
    "block_3_4_b = tf.keras.layers.Activation('gelu')(block_3_4_b)\n",
    "\n",
    "block_3_4_b = tf.keras.layers.AveragePooling1D(pool_size=2, padding='SAME')(block_3_4_b)\n",
    "\n",
    "preblock_c = tf.keras.layers.Conv1D(filters=64, kernel_size=7, padding='SAME')(inputs2)\n",
    "preblock_c = tf.keras.layers.BatchNormalization()(preblock_c)\n",
    "preblock_c = tf.keras.layers.Activation('gelu')(preblock_c)\n",
    "preblock_c = tf.keras.layers.MaxPool1D(pool_size=2, padding='SAME')(preblock_c)\n",
    "\n",
    "\n",
    "# block 1\n",
    "block_1_1_c = tf.keras.layers.Conv1D(filters=64, kernel_size=3, padding='SAME')(preblock_c)\n",
    "block_1_1_c = tf.keras.layers.BatchNormalization()(block_1_1_c)\n",
    "block_1_1_c = tf.keras.layers.Activation('gelu')(block_1_1_c)\n",
    "block_1_1_c = tf.keras.layers.Conv1D(filters=64, kernel_size=3, padding='SAME')(block_1_1_c)\n",
    "block_1_1_c = tf.keras.layers.BatchNormalization()(block_1_1_c)\n",
    "block_1_1_c = tf.keras.layers.Concatenate()([block_1_1_c, preblock_c])\n",
    "block_1_1_c = tf.keras.layers.Activation('gelu')(block_1_1_c)\n",
    "\n",
    "block_1_2_c = tf.keras.layers.Conv1D(filters=128, kernel_size=3, padding='SAME')(block_1_1_c)\n",
    "block_1_2_c = tf.keras.layers.BatchNormalization()(block_1_2_c)\n",
    "block_1_2_c = tf.keras.layers.Activation('gelu')(block_1_2_c)\n",
    "block_1_2_c = tf.keras.layers.Conv1D(filters=128, kernel_size=3, padding='SAME')(block_1_2_c)\n",
    "block_1_2_c = tf.keras.layers.BatchNormalization()(block_1_2_c)\n",
    "block_1_2_c = tf.keras.layers.Concatenate()([block_1_2_c, block_1_1_c])\n",
    "block_1_2_c = tf.keras.layers.Activation('gelu')(block_1_2_c)\n",
    "\n",
    "block_1_3_c = tf.keras.layers.Conv1D(filters=256, kernel_size=3, padding='SAME')(block_1_2_c)\n",
    "block_1_3_c = tf.keras.layers.BatchNormalization()(block_1_3_c)\n",
    "block_1_3_c = tf.keras.layers.Activation('gelu')(block_1_3_c)\n",
    "block_1_3_c = tf.keras.layers.Conv1D(filters=256, kernel_size=3, padding='SAME')(block_1_3_c)\n",
    "block_1_3_c = tf.keras.layers.BatchNormalization()(block_1_3_c)\n",
    "block_1_3_c = tf.keras.layers.Concatenate()([block_1_3_c, block_1_2_c])\n",
    "block_1_3_c = tf.keras.layers.Activation('gelu')(block_1_3_c)\n",
    "\n",
    "block_1_4_c = tf.keras.layers.Conv1D(filters=512, kernel_size=3, padding='SAME')(block_1_3_c)\n",
    "block_1_4_c = tf.keras.layers.BatchNormalization()(block_1_4_c)\n",
    "block_1_4_c = tf.keras.layers.Activation('gelu')(block_1_4_c)\n",
    "block_1_4_c = tf.keras.layers.Conv1D(filters=512, kernel_size=3, padding='SAME')(block_1_4_c)\n",
    "block_1_4_c = tf.keras.layers.BatchNormalization()(block_1_4_c)\n",
    "block_1_4_c = tf.keras.layers.Concatenate()([block_1_4_c, block_1_3_c])\n",
    "block_1_4_c = tf.keras.layers.Activation('gelu')(block_1_4_c)\n",
    "\n",
    "block_1_4_c = tf.keras.layers.AveragePooling1D(pool_size=2, padding='SAME')(block_1_4_c)\n",
    "\n",
    "\n",
    "# block 2\n",
    "block_2_1_c = tf.keras.layers.Conv1D(filters=64, kernel_size=5, padding='SAME')(preblock_c)\n",
    "block_2_1_c = tf.keras.layers.BatchNormalization()(block_2_1_c)\n",
    "block_2_1_c = tf.keras.layers.Activation('gelu')(block_2_1_c)\n",
    "block_2_1_c = tf.keras.layers.Conv1D(filters=64, kernel_size=5, padding='SAME')(block_2_1_c)\n",
    "block_2_1_c = tf.keras.layers.BatchNormalization()(block_2_1_c)\n",
    "block_2_1_c = tf.keras.layers.Concatenate()([block_2_1_c, preblock_c])\n",
    "block_2_1_c = tf.keras.layers.Activation('gelu')(block_2_1_c)\n",
    "\n",
    "block_2_2_c = tf.keras.layers.Conv1D(filters=128, kernel_size=5, padding='SAME')(block_2_1_c)\n",
    "block_2_2_c = tf.keras.layers.BatchNormalization()(block_2_2_c)\n",
    "block_2_2_c = tf.keras.layers.Activation('gelu')(block_2_2_c)\n",
    "block_2_2_c = tf.keras.layers.Conv1D(filters=128, kernel_size=5, padding='SAME')(block_2_2_c)\n",
    "block_2_2_c = tf.keras.layers.BatchNormalization()(block_2_2_c)\n",
    "block_2_2_c = tf.keras.layers.Concatenate()([block_2_2_c, block_2_1_c])\n",
    "block_2_2_c = tf.keras.layers.Activation('gelu')(block_2_2_c)\n",
    "\n",
    "block_2_3_c = tf.keras.layers.Conv1D(filters=256, kernel_size=5, padding='SAME')(block_2_2_c)\n",
    "block_2_3_c = tf.keras.layers.BatchNormalization()(block_2_3_c)\n",
    "block_2_3_c = tf.keras.layers.Activation('gelu')(block_2_3_c)\n",
    "block_2_3_c = tf.keras.layers.Conv1D(filters=256, kernel_size=5, padding='SAME')(block_2_3_c)\n",
    "block_2_3_c = tf.keras.layers.BatchNormalization()(block_2_3_c)\n",
    "block_2_3_c = tf.keras.layers.Concatenate()([block_2_3_c, block_2_2_c])\n",
    "block_2_3_c = tf.keras.layers.Activation('gelu')(block_2_3_c)\n",
    "\n",
    "block_2_4_c = tf.keras.layers.Conv1D(filters=512, kernel_size=5, padding='SAME')(block_2_3_c)\n",
    "block_2_4_c = tf.keras.layers.BatchNormalization()(block_2_4_c)\n",
    "block_2_4_c = tf.keras.layers.Activation('gelu')(block_2_4_c)\n",
    "block_2_4_c = tf.keras.layers.Conv1D(filters=512, kernel_size=5, padding='SAME')(block_2_4_c)\n",
    "block_2_4_c = tf.keras.layers.BatchNormalization()(block_2_4_c)\n",
    "block_2_4_c = tf.keras.layers.Concatenate()([block_2_4_c, block_2_3_c])\n",
    "block_2_4_c = tf.keras.layers.Activation('gelu')(block_2_4_c)\n",
    "\n",
    "block_2_4_c = tf.keras.layers.AveragePooling1D(pool_size=2, padding='SAME')(block_2_4_c)\n",
    "\n",
    "# block 3\n",
    "block_3_1_c = tf.keras.layers.Conv1D(filters=64, kernel_size=7, padding='SAME')(preblock_c)\n",
    "block_3_1_c = tf.keras.layers.BatchNormalization()(block_3_1_c)\n",
    "block_3_1_c = tf.keras.layers.Activation('gelu')(block_3_1_c)\n",
    "block_3_1_c = tf.keras.layers.Conv1D(filters=64, kernel_size=7, padding='SAME')(block_3_1_c)\n",
    "block_3_1_c = tf.keras.layers.BatchNormalization()(block_3_1_c)\n",
    "block_3_1_c = tf.keras.layers.Concatenate()([block_3_1_c, preblock_c])\n",
    "block_3_1_c = tf.keras.layers.Activation('gelu')(block_3_1_c)\n",
    "\n",
    "block_3_2_c = tf.keras.layers.Conv1D(filters=128, kernel_size=7, padding='SAME')(block_3_1_c)\n",
    "block_3_2_c = tf.keras.layers.BatchNormalization()(block_3_2_c)\n",
    "block_3_2_c = tf.keras.layers.Activation('gelu')(block_3_2_c)\n",
    "block_3_2_c = tf.keras.layers.Conv1D(filters=128, kernel_size=7, padding='SAME')(block_3_2_c)\n",
    "block_3_2_c = tf.keras.layers.BatchNormalization()(block_3_2_c)\n",
    "block_3_2_c = tf.keras.layers.Concatenate()([block_3_2_c, block_3_1_c])\n",
    "block_3_2_c = tf.keras.layers.Activation('gelu')(block_3_2_c)\n",
    "\n",
    "block_3_3_c = tf.keras.layers.Conv1D(filters=256, kernel_size=7, padding='SAME')(block_3_2_c)\n",
    "block_3_3_c = tf.keras.layers.BatchNormalization()(block_3_3_c)\n",
    "block_3_3_c = tf.keras.layers.Activation('gelu')(block_3_3_c)\n",
    "block_3_3_c = tf.keras.layers.Conv1D(filters=256, kernel_size=7, padding='SAME')(block_3_3_c)\n",
    "block_3_3_c = tf.keras.layers.BatchNormalization()(block_3_3_c)\n",
    "block_3_3_c = tf.keras.layers.Concatenate()([block_3_3_c, block_3_2_c])\n",
    "block_3_3_c = tf.keras.layers.Activation('gelu')(block_3_3_c)\n",
    "\n",
    "block_3_4_c = tf.keras.layers.Conv1D(filters=512, kernel_size=7, padding='SAME')(block_3_3_c)\n",
    "block_3_4_c = tf.keras.layers.BatchNormalization()(block_3_4_c)\n",
    "block_3_4_c = tf.keras.layers.Activation('gelu')(block_3_4_c)\n",
    "block_3_4_c = tf.keras.layers.Conv1D(filters=512, kernel_size=7, padding='SAME')(block_3_4_c)\n",
    "block_3_4_c = tf.keras.layers.BatchNormalization()(block_3_4_c)\n",
    "block_3_4_c = tf.keras.layers.Concatenate()([block_3_4_c, block_3_3_c])\n",
    "block_3_4_c = tf.keras.layers.Activation('gelu')(block_3_4_c)\n",
    "\n",
    "block_3_4_c = tf.keras.layers.AveragePooling1D(pool_size=2, padding='SAME')(block_3_4_c)\n",
    "\n",
    "output_layer = tf.keras.layers.Concatenate()([block_1_4_a, block_2_4_a, block_3_4_a, block_1_4_b, block_2_4_b, block_3_4_b, block_1_4_c, block_2_4_c, block_3_4_c])\n",
    "\n",
    "# output_layer = tf.keras.layers.Concatenate()([block_1_4_a, block_2_4_a, block_3_4_a,])\n",
    "output_layer = tf.keras.layers.Flatten()(output_layer)\n",
    "output_layer = tf.keras.layers.Dense(n_classes)(output_layer)\n",
    "output_layer = tf.keras.layers.Activation('tanh')(output_layer)\n",
    "# output_layer = tf.keras.layers.Dropout(0.8)(output_layer)\n",
    "output_layer = tf.keras.layers.Dense(n_classes)(output_layer)\n",
    "output_layer = tf.keras.layers.LeakyReLU(0.2)(output_layer)\n",
    "# output_layer = tf.keras.layers.Dropout(0.8)(output_layer)\n",
    "output_layer = tf.keras.layers.Dense(n_classes)(output_layer)\n",
    "output_layer = tf.keras.layers.Activation('softmax')(output_layer)\n",
    "# output_layer = tf.keras.layers.Dropout(0.8)(output_layer)\n",
    "# output_layer = tf.keras.layers.Dense(n_classes)(output_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "019100bb-960f-46a6-b930-369e127bb76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=inputs, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c890ca85-f37e-4954-9281-1a6da3e4a80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE, amsgrad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92b12af3-56df-427b-8cad-70e2897bf27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer, \n",
    "              tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), \n",
    "              metrics=['sparse_categorical_accuracy'],\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5f323ed-7383-467f-ad16-0078ec6e4080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2aa3bfb-3d4d-41fe-82ae-b652ef196245",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_callback = KerasSequenceValidater(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61e860a4-38c9-4264-867b-6113ca64b7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-18 12:55:11.337840: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8201\n",
      "2022-05-18 12:55:11.961686: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-05-18 12:55:13.368347: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "817/817 [==============================] - ETA: 0s - loss: 6.7561 - sparse_categorical_accuracy: 0.0444{'val_loss': 29.915607, 'val_sparse_categorical_accuracy': 0.042194776}\n",
      "817/817 [==============================] - 686s 804ms/step - loss: 6.7561 - sparse_categorical_accuracy: 0.0444 - val_loss: 29.9156 - val_sparse_categorical_accuracy: 0.0422\n",
      "Epoch 2/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 5.7349 - sparse_categorical_accuracy: 0.0483{'val_loss': 28.948061, 'val_sparse_categorical_accuracy': 0.045953836}\n",
      "817/817 [==============================] - 650s 796ms/step - loss: 5.7349 - sparse_categorical_accuracy: 0.0483 - val_loss: 28.9481 - val_sparse_categorical_accuracy: 0.0460\n",
      "Epoch 3/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 5.4967 - sparse_categorical_accuracy: 0.0553{'val_loss': 28.722328, 'val_sparse_categorical_accuracy': 0.052483737}\n",
      "817/817 [==============================] - 650s 796ms/step - loss: 5.4967 - sparse_categorical_accuracy: 0.0553 - val_loss: 28.7223 - val_sparse_categorical_accuracy: 0.0525\n",
      "Epoch 4/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 5.4896 - sparse_categorical_accuracy: 0.0715{'val_loss': 28.715628, 'val_sparse_categorical_accuracy': 0.06785185}\n",
      "817/817 [==============================] - 650s 795ms/step - loss: 5.4896 - sparse_categorical_accuracy: 0.0715 - val_loss: 28.7156 - val_sparse_categorical_accuracy: 0.0679\n",
      "Epoch 5/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 5.3875 - sparse_categorical_accuracy: 0.0641{'val_loss': 28.618887, 'val_sparse_categorical_accuracy': 0.060802694}\n",
      "817/817 [==============================] - 649s 794ms/step - loss: 5.3875 - sparse_categorical_accuracy: 0.0641 - val_loss: 28.6189 - val_sparse_categorical_accuracy: 0.0608\n",
      "Epoch 6/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 5.0705 - sparse_categorical_accuracy: 0.0660{'val_loss': 28.318539, 'val_sparse_categorical_accuracy': 0.06261505}\n",
      "817/817 [==============================] - 649s 794ms/step - loss: 5.0705 - sparse_categorical_accuracy: 0.0660 - val_loss: 28.3185 - val_sparse_categorical_accuracy: 0.0626\n",
      "Epoch 7/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 5.0848 - sparse_categorical_accuracy: 0.0685{'val_loss': 28.332031, 'val_sparse_categorical_accuracy': 0.06500884}\n",
      "817/817 [==============================] - 650s 795ms/step - loss: 5.0848 - sparse_categorical_accuracy: 0.0685 - val_loss: 28.3320 - val_sparse_categorical_accuracy: 0.0650\n",
      "Epoch 8/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 4.8196 - sparse_categorical_accuracy: 0.0767{'val_loss': 28.080797, 'val_sparse_categorical_accuracy': 0.072829016}\n",
      "817/817 [==============================] - 650s 795ms/step - loss: 4.8196 - sparse_categorical_accuracy: 0.0767 - val_loss: 28.0808 - val_sparse_categorical_accuracy: 0.0728\n",
      "Epoch 9/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 4.9453 - sparse_categorical_accuracy: 0.0837{'val_loss': 28.199846, 'val_sparse_categorical_accuracy': 0.07942258}\n",
      "817/817 [==============================] - 650s 795ms/step - loss: 4.9453 - sparse_categorical_accuracy: 0.0837 - val_loss: 28.1998 - val_sparse_categorical_accuracy: 0.0794\n",
      "Epoch 10/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 4.7875 - sparse_categorical_accuracy: 0.0771{'val_loss': 28.050406, 'val_sparse_categorical_accuracy': 0.07317391}\n",
      "817/817 [==============================] - 650s 795ms/step - loss: 4.7875 - sparse_categorical_accuracy: 0.0771 - val_loss: 28.0504 - val_sparse_categorical_accuracy: 0.0732\n",
      "Epoch 11/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 4.8722 - sparse_categorical_accuracy: 0.0903{'val_loss': 28.130594, 'val_sparse_categorical_accuracy': 0.08568733}\n",
      "817/817 [==============================] - 650s 796ms/step - loss: 4.8722 - sparse_categorical_accuracy: 0.0903 - val_loss: 28.1306 - val_sparse_categorical_accuracy: 0.0857\n",
      "Epoch 12/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 4.9194 - sparse_categorical_accuracy: 0.0913{'val_loss': 28.175335, 'val_sparse_categorical_accuracy': 0.08666337}\n",
      "817/817 [==============================] - 649s 795ms/step - loss: 4.9194 - sparse_categorical_accuracy: 0.0913 - val_loss: 28.1753 - val_sparse_categorical_accuracy: 0.0867\n",
      "Epoch 13/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 4.8321 - sparse_categorical_accuracy: 0.0865{'val_loss': 28.092636, 'val_sparse_categorical_accuracy': 0.08208818}\n",
      "817/817 [==============================] - 650s 795ms/step - loss: 4.8321 - sparse_categorical_accuracy: 0.0865 - val_loss: 28.0926 - val_sparse_categorical_accuracy: 0.0821\n",
      "Epoch 14/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 4.8314 - sparse_categorical_accuracy: 0.0906{'val_loss': 28.09199, 'val_sparse_categorical_accuracy': 0.085996315}\n",
      "817/817 [==============================] - 649s 795ms/step - loss: 4.8314 - sparse_categorical_accuracy: 0.0906 - val_loss: 28.0920 - val_sparse_categorical_accuracy: 0.0860\n",
      "Epoch 15/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 4.8158 - sparse_categorical_accuracy: 0.0973{'val_loss': 28.0772, 'val_sparse_categorical_accuracy': 0.09237381}\n",
      "817/817 [==============================] - 650s 796ms/step - loss: 4.8158 - sparse_categorical_accuracy: 0.0973 - val_loss: 28.0772 - val_sparse_categorical_accuracy: 0.0924\n",
      "Epoch 16/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 4.9966 - sparse_categorical_accuracy: 0.0793{'val_loss': 28.248459, 'val_sparse_categorical_accuracy': 0.07531898}\n",
      "817/817 [==============================] - 649s 794ms/step - loss: 4.9966 - sparse_categorical_accuracy: 0.0793 - val_loss: 28.2485 - val_sparse_categorical_accuracy: 0.0753\n",
      "Epoch 17/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 4.7522 - sparse_categorical_accuracy: 0.0912{'val_loss': 28.016949, 'val_sparse_categorical_accuracy': 0.08658972}\n",
      "817/817 [==============================] - 648s 793ms/step - loss: 4.7522 - sparse_categorical_accuracy: 0.0912 - val_loss: 28.0169 - val_sparse_categorical_accuracy: 0.0866\n",
      "Epoch 18/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 4.8309 - sparse_categorical_accuracy: 0.0882{'val_loss': 28.0915, 'val_sparse_categorical_accuracy': 0.08375288}\n",
      "817/817 [==============================] - 647s 792ms/step - loss: 4.8309 - sparse_categorical_accuracy: 0.0882 - val_loss: 28.0915 - val_sparse_categorical_accuracy: 0.0838\n",
      "Epoch 19/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 4.9963 - sparse_categorical_accuracy: 0.0804{'val_loss': 28.248222, 'val_sparse_categorical_accuracy': 0.07634573}\n",
      "817/817 [==============================] - 647s 792ms/step - loss: 4.9963 - sparse_categorical_accuracy: 0.0804 - val_loss: 28.2482 - val_sparse_categorical_accuracy: 0.0763\n",
      "Epoch 20/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 4.8437 - sparse_categorical_accuracy: 0.0867{'val_loss': 28.10358, 'val_sparse_categorical_accuracy': 0.08232274}\n",
      "817/817 [==============================] - 647s 792ms/step - loss: 4.8437 - sparse_categorical_accuracy: 0.0867 - val_loss: 28.1036 - val_sparse_categorical_accuracy: 0.0823\n",
      "Epoch 21/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 4.7467 - sparse_categorical_accuracy: 0.0861{'val_loss': 28.01168, 'val_sparse_categorical_accuracy': 0.081811346}\n",
      "817/817 [==============================] - 647s 792ms/step - loss: 4.7467 - sparse_categorical_accuracy: 0.0861 - val_loss: 28.0117 - val_sparse_categorical_accuracy: 0.0818\n",
      "Epoch 22/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 4.9089 - sparse_categorical_accuracy: 0.0897{'val_loss': 28.165365, 'val_sparse_categorical_accuracy': 0.08516008}\n",
      "817/817 [==============================] - 648s 793ms/step - loss: 4.9089 - sparse_categorical_accuracy: 0.0897 - val_loss: 28.1654 - val_sparse_categorical_accuracy: 0.0852\n",
      "Epoch 23/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 4.8347 - sparse_categorical_accuracy: 0.0875{'val_loss': 28.095112, 'val_sparse_categorical_accuracy': 0.083116345}\n",
      "817/817 [==============================] - 647s 792ms/step - loss: 4.8347 - sparse_categorical_accuracy: 0.0875 - val_loss: 28.0951 - val_sparse_categorical_accuracy: 0.0831\n",
      "Epoch 24/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 4.6720 - sparse_categorical_accuracy: 0.1006{'val_loss': 27.940977, 'val_sparse_categorical_accuracy': 0.095523044}\n",
      "817/817 [==============================] - 648s 793ms/step - loss: 4.6720 - sparse_categorical_accuracy: 0.1006 - val_loss: 27.9410 - val_sparse_categorical_accuracy: 0.0955\n",
      "Epoch 25/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 4.7311 - sparse_categorical_accuracy: 0.0987{'val_loss': 27.996908, 'val_sparse_categorical_accuracy': 0.0936871}\n",
      "817/817 [==============================] - 648s 793ms/step - loss: 4.7311 - sparse_categorical_accuracy: 0.0987 - val_loss: 27.9969 - val_sparse_categorical_accuracy: 0.0937\n",
      "Epoch 26/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 4.9337 - sparse_categorical_accuracy: 0.1007{'val_loss': 28.188902, 'val_sparse_categorical_accuracy': 0.09557354}\n",
      "817/817 [==============================] - 647s 792ms/step - loss: 4.9337 - sparse_categorical_accuracy: 0.1007 - val_loss: 28.1889 - val_sparse_categorical_accuracy: 0.0956\n",
      "Epoch 27/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 4.9737 - sparse_categorical_accuracy: 0.1033{'val_loss': 28.22676, 'val_sparse_categorical_accuracy': 0.09810812}\n",
      "817/817 [==============================] - 648s 793ms/step - loss: 4.9737 - sparse_categorical_accuracy: 0.1033 - val_loss: 28.2268 - val_sparse_categorical_accuracy: 0.0981\n",
      "Epoch 28/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 5.2470 - sparse_categorical_accuracy: 0.1104{'val_loss': 28.48578, 'val_sparse_categorical_accuracy': 0.10468901}\n",
      "817/817 [==============================] - 647s 792ms/step - loss: 5.2470 - sparse_categorical_accuracy: 0.1104 - val_loss: 28.4858 - val_sparse_categorical_accuracy: 0.1047\n",
      "Epoch 29/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 5.3677 - sparse_categorical_accuracy: 0.1035{'val_loss': 28.600122, 'val_sparse_categorical_accuracy': 0.098142676}\n",
      "817/817 [==============================] - 648s 793ms/step - loss: 5.3677 - sparse_categorical_accuracy: 0.1035 - val_loss: 28.6001 - val_sparse_categorical_accuracy: 0.0981\n",
      "Epoch 30/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 5.1161 - sparse_categorical_accuracy: 0.1125{'val_loss': 28.36168, 'val_sparse_categorical_accuracy': 0.10668472}\n",
      "817/817 [==============================] - 648s 793ms/step - loss: 5.1161 - sparse_categorical_accuracy: 0.1125 - val_loss: 28.3617 - val_sparse_categorical_accuracy: 0.1067\n",
      "Epoch 31/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 5.1043 - sparse_categorical_accuracy: 0.1100{'val_loss': 28.350502, 'val_sparse_categorical_accuracy': 0.104343474}\n",
      "817/817 [==============================] - 647s 792ms/step - loss: 5.1043 - sparse_categorical_accuracy: 0.1100 - val_loss: 28.3505 - val_sparse_categorical_accuracy: 0.1043\n",
      "Epoch 32/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 5.3185 - sparse_categorical_accuracy: 0.1102{'val_loss': 28.553507, 'val_sparse_categorical_accuracy': 0.104699984}\n",
      "817/817 [==============================] - 650s 795ms/step - loss: 5.3185 - sparse_categorical_accuracy: 0.1102 - val_loss: 28.5535 - val_sparse_categorical_accuracy: 0.1047\n",
      "Epoch 33/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 5.5307 - sparse_categorical_accuracy: 0.1067{'val_loss': 28.754503, 'val_sparse_categorical_accuracy': 0.10121995}\n",
      "817/817 [==============================] - 650s 795ms/step - loss: 5.5307 - sparse_categorical_accuracy: 0.1067 - val_loss: 28.7545 - val_sparse_categorical_accuracy: 0.1012\n",
      "Epoch 34/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 5.2500 - sparse_categorical_accuracy: 0.1041{'val_loss': 28.48859, 'val_sparse_categorical_accuracy': 0.098692104}\n",
      "817/817 [==============================] - 649s 794ms/step - loss: 5.2500 - sparse_categorical_accuracy: 0.1041 - val_loss: 28.4886 - val_sparse_categorical_accuracy: 0.0987\n",
      "Epoch 35/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 5.5311 - sparse_categorical_accuracy: 0.1048{'val_loss': 28.754915, 'val_sparse_categorical_accuracy': 0.09942672}\n",
      "817/817 [==============================] - 648s 792ms/step - loss: 5.5311 - sparse_categorical_accuracy: 0.1048 - val_loss: 28.7549 - val_sparse_categorical_accuracy: 0.0994\n",
      "Epoch 36/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 5.5970 - sparse_categorical_accuracy: 0.0963{'val_loss': 28.817362, 'val_sparse_categorical_accuracy': 0.0914222}\n",
      "817/817 [==============================] - 648s 792ms/step - loss: 5.5970 - sparse_categorical_accuracy: 0.0963 - val_loss: 28.8174 - val_sparse_categorical_accuracy: 0.0914\n",
      "Epoch 37/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 5.3697 - sparse_categorical_accuracy: 0.1064{'val_loss': 28.601995, 'val_sparse_categorical_accuracy': 0.100964084}\n",
      "817/817 [==============================] - 648s 792ms/step - loss: 5.3697 - sparse_categorical_accuracy: 0.1064 - val_loss: 28.6020 - val_sparse_categorical_accuracy: 0.1010\n",
      "Epoch 38/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 5.2478 - sparse_categorical_accuracy: 0.1043{'val_loss': 28.48653, 'val_sparse_categorical_accuracy': 0.09902368}\n",
      "817/817 [==============================] - 648s 793ms/step - loss: 5.2478 - sparse_categorical_accuracy: 0.1043 - val_loss: 28.4865 - val_sparse_categorical_accuracy: 0.0990\n",
      "Epoch 39/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 5.2136 - sparse_categorical_accuracy: 0.1121{'val_loss': 28.454062, 'val_sparse_categorical_accuracy': 0.10634769}\n",
      "817/817 [==============================] - 647s 792ms/step - loss: 5.2136 - sparse_categorical_accuracy: 0.1121 - val_loss: 28.4541 - val_sparse_categorical_accuracy: 0.1063\n",
      "Epoch 40/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 5.3792 - sparse_categorical_accuracy: 0.1071{'val_loss': 28.610975, 'val_sparse_categorical_accuracy': 0.10157717}\n",
      "817/817 [==============================] - 648s 792ms/step - loss: 5.3792 - sparse_categorical_accuracy: 0.1071 - val_loss: 28.6110 - val_sparse_categorical_accuracy: 0.1016\n",
      "Epoch 41/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 5.3656 - sparse_categorical_accuracy: 0.1142{'val_loss': 28.598108, 'val_sparse_categorical_accuracy': 0.10834241}\n",
      "817/817 [==============================] - 648s 792ms/step - loss: 5.3656 - sparse_categorical_accuracy: 0.1142 - val_loss: 28.5981 - val_sparse_categorical_accuracy: 0.1083\n",
      "Epoch 42/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 5.2945 - sparse_categorical_accuracy: 0.1202{'val_loss': 28.53072, 'val_sparse_categorical_accuracy': 0.11406687}\n",
      "817/817 [==============================] - 647s 792ms/step - loss: 5.2945 - sparse_categorical_accuracy: 0.1202 - val_loss: 28.5307 - val_sparse_categorical_accuracy: 0.1141\n",
      "Epoch 43/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 5.3421 - sparse_categorical_accuracy: 0.1131{'val_loss': 28.575836, 'val_sparse_categorical_accuracy': 0.10727479}\n",
      "817/817 [==============================] - 648s 792ms/step - loss: 5.3421 - sparse_categorical_accuracy: 0.1131 - val_loss: 28.5758 - val_sparse_categorical_accuracy: 0.1073\n",
      "Epoch 44/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 5.0931 - sparse_categorical_accuracy: 0.1289{'val_loss': 28.339878, 'val_sparse_categorical_accuracy': 0.12226819}\n",
      "817/817 [==============================] - 647s 792ms/step - loss: 5.0931 - sparse_categorical_accuracy: 0.1289 - val_loss: 28.3399 - val_sparse_categorical_accuracy: 0.1223\n",
      "Epoch 45/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 5.4735 - sparse_categorical_accuracy: 0.1226{'val_loss': 28.700298, 'val_sparse_categorical_accuracy': 0.116303295}\n",
      "817/817 [==============================] - 648s 792ms/step - loss: 5.4735 - sparse_categorical_accuracy: 0.1226 - val_loss: 28.7003 - val_sparse_categorical_accuracy: 0.1163\n",
      "Epoch 46/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 5.3450 - sparse_categorical_accuracy: 0.1193{'val_loss': 28.578638, 'val_sparse_categorical_accuracy': 0.11319854}\n",
      "817/817 [==============================] - 648s 793ms/step - loss: 5.3450 - sparse_categorical_accuracy: 0.1193 - val_loss: 28.5786 - val_sparse_categorical_accuracy: 0.1132\n",
      "Epoch 47/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 5.1865 - sparse_categorical_accuracy: 0.1209{'val_loss': 28.42841, 'val_sparse_categorical_accuracy': 0.114724785}\n",
      "817/817 [==============================] - 648s 793ms/step - loss: 5.1865 - sparse_categorical_accuracy: 0.1209 - val_loss: 28.4284 - val_sparse_categorical_accuracy: 0.1147\n",
      "Epoch 48/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 5.3386 - sparse_categorical_accuracy: 0.1153{'val_loss': 28.572485, 'val_sparse_categorical_accuracy': 0.10931852}\n",
      "817/817 [==============================] - 647s 792ms/step - loss: 5.3386 - sparse_categorical_accuracy: 0.1153 - val_loss: 28.5725 - val_sparse_categorical_accuracy: 0.1093\n",
      "Epoch 49/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 5.3966 - sparse_categorical_accuracy: 0.1267{'val_loss': 28.627493, 'val_sparse_categorical_accuracy': 0.12018006}\n",
      "817/817 [==============================] - 648s 792ms/step - loss: 5.3966 - sparse_categorical_accuracy: 0.1267 - val_loss: 28.6275 - val_sparse_categorical_accuracy: 0.1202\n",
      "Epoch 50/50\n",
      "817/817 [==============================] - ETA: 0s - loss: 5.5718 - sparse_categorical_accuracy: 0.1166{'val_loss': 28.793491, 'val_sparse_categorical_accuracy': 0.11063259}\n",
      "817/817 [==============================] - 648s 792ms/step - loss: 5.5718 - sparse_categorical_accuracy: 0.1166 - val_loss: 28.7935 - val_sparse_categorical_accuracy: 0.1106\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    # validation_data = valid_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[validation_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55314bf-db6a-47fa-a493-bf76afe6c389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7e7f39-0641-4832-b4a8-96975317224e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14e53c89-a383-4a1f-884f-75c6cfecbf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2d92b7-f2d0-400b-a58d-4229cbd43a1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
